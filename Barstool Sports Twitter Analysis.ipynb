{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Function To Pull Tweets From A Specified User Using Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import re\n",
    "\n",
    "# Twitter API credentials\n",
    "consumer_key = \"1kmJBTjd214v2eVIi7tUDpzdr\"\n",
    "consumer_secret = \"M4Pqx3Yvxid1yIWFJBAPwdYxJpP3XlBwtd3bfywndxI0QswpGk\"\n",
    "access_key = \"276159644-CGZeVcjXsbNetX4JFlXe3ML4wZitAOdunbHGOazM\"\n",
    "access_secret = \"yPltYhYf7nIH3TGbNwrTvxtCzOhNukuw9gIf2LfZEjbMy\"\n",
    "\n",
    "\n",
    "def get_all_tweets(screen_name):\n",
    "    \n",
    "    # Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "\n",
    "    # Authorize Twitter, initialize Tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    # Create a list to hold all the tweets\n",
    "    alltweets = []\n",
    "\n",
    "    # Make initial request for most recent tweets\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name, count = 200, include_rts = False)\n",
    "\n",
    "    # Store tweets in list\n",
    "    alltweets.extend(new_tweets)\n",
    "\n",
    "    # Save the id of the oldest tweet minus one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    # Keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print (\"getting tweets before %s\" % (oldest))\n",
    "\n",
    "        # All subsequent requests use the max_id parameter to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name, count = 200, max_id = oldest)\n",
    "\n",
    "        # Save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        # Update the ID of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        print (\"...%s tweets downloaded so far\"  % (len(alltweets)))\n",
    "\n",
    "    # Create list to hold the 'text' portion of the tweet's JSON data\n",
    "    outtweets = []\n",
    "    for tweet in alltweets :\n",
    "       outtweets.append(tweet.text)\n",
    "\n",
    "    # Test the output for 'outtweets' \n",
    "    print()\n",
    "    print(outtweets[:10])\n",
    "    print()\n",
    "    print(len(outtweets))\n",
    "    \n",
    "    # Write tweets to text file, with one word on each line\n",
    "    output_file_name = screen_name + \"_tweets.txt\"\n",
    "    delimiter = \"\\n\"\n",
    "\n",
    "    with open(output_file_name, 'w') as f:\n",
    "            f.write(delimiter.join(word for word in outtweets))\n",
    "    \n",
    "\n",
    "    \n",
    "                \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #pass in the username of the account you want to download\n",
    "    get_all_tweets(\"UncleChaps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take Words From Text File, Append To List, and Modify Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = \"/Users/MikeRalston/Desktop/ADA/API : Text Mining Final Project/\"\n",
    "\n",
    "# Create list to store words from text file\n",
    "tweet_words = []\n",
    "\n",
    "# Open specified user's tweet file, split each line up, and append 'tweet_words' with contents of 'line'\n",
    "with open(wd + \"UncleChaps_tweets.txt\", 'r') as input_file:\n",
    "    for idx, line in enumerate(input_file.readlines()):\n",
    "        line = line.strip()\n",
    "        tweet_words.append(line)\n",
    "        \n",
    "# Split line up into individual words, cast to lowercase, remove empty strings \n",
    "tweet_words = [word for word in tweet_words for word in word.split()]\n",
    "tweet_words = [word.lower() for word in tweet_words] \n",
    "tweet_words = [word for word in tweet_words if word]\n",
    "\n",
    "# Remove links, remove mentions, remove hashtags\n",
    "tweet_words = [word for word in tweet_words if \"http\" not in word ]\n",
    "tweet_words = [word for word in tweet_words if \"@\" not in word ]\n",
    "tweet_words = [word for word in tweet_words if \"#\" not in word ]\n",
    "\n",
    "# Remove punctuation\n",
    "tweet_words = [word.replace(\"'\", \"\") for word in tweet_words]\n",
    "tweet_words = [word.replace(\".\", \"\") for word in tweet_words]\n",
    "tweet_words = [word.replace(\",\", \"\") for word in tweet_words]\n",
    "tweet_words = [word.replace(\":\", \"\") for word in tweet_words]\n",
    "tweet_words = [word.replace(\"-\", \"\") for word in tweet_words]\n",
    "tweet_words = [word.replace(\"'\", \"\") for word in tweet_words]\n",
    "\n",
    "# Test output of 'tweet_words'\n",
    "print(tweet_words[:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dictionary To Hold Word-Scores From Tidytext Sentiment Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to hold sentiment scores\n",
    "sentiment_scores = {}\n",
    "\n",
    "# If word from tweet_words appears in the sentiments file, the appropriaye score is assigned\n",
    "with open(wd + \"tidytext_sentiments.txt\",'r') as infile :\n",
    "    next(infile)\n",
    "    for line in infile.readlines() :\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        if line[1] == \"positive\" :\n",
    "            sentiment_scores[line[0]] = 1\n",
    "        else :\n",
    "            sentiment_scores[line[0]] = -1\n",
    "\n",
    "\n",
    "# Test scoring system for words\n",
    "for idx, word in enumerate(sentiment_scores) :\n",
    "    print(\"{} has score {}.\".format(word,sentiment_scores[word]))\n",
    "    if idx > 10 :\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Tweet_Words[ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list with the same length as the tweet_words list\n",
    "scores = [0] * len(tweet_words)\n",
    "\n",
    "# Set current score to zero\n",
    "current_score = 0 \n",
    "\n",
    "# Iterate over each word in tweet_words and keep and running score of the words\n",
    "for idx, word in enumerate(tweet_words) :\n",
    "    if word in sentiment_scores :\n",
    "        current_score += sentiment_scores[word.lower()]\n",
    "   \n",
    "    scores[idx] = current_score\n",
    "\n",
    "# Write results out to a text file for input into R/GGPlot\n",
    "with open(wd + \"UncleChaps_tweet_scores.txt\",'w') as ofile :\n",
    "    ofile.write(\"word\\tscore\\n\")\n",
    "    for idx, score in enumerate(scores) :\n",
    "        ofile.write(\"\\t\".join([str(idx+1),str(score)]) + \"\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
